{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOkJNEC4H471a51PMKF7rc/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AlSYiCJmf5C","executionInfo":{"status":"ok","timestamp":1724775059877,"user_tz":-420,"elapsed":9663,"user":{"displayName":"Tanutpong Kunakornkasem","userId":"13209845585212162523"}},"outputId":"ddf3a413-d530-4941-c59d-53c42e235300"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ipython-autotime\n","  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (71.0.4)\n","Collecting jedi>=0.16 (from ipython->ipython-autotime)\n","  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n","Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n","Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","Installing collected packages: jedi, ipython-autotime\n","Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n","time: 297 Âµs (started: 2024-08-27 16:10:59 +00:00)\n"]}],"source":["!pip install ipython-autotime\n","%load_ext autotime"]},{"cell_type":"code","source":["# Stochastic Gradient descent (Multiple linear regression)\n","import numpy as np\n","\n","x = np.array([[0,1],[2,6],[3,8]]) #x1, x2\n","y = np.array([1,1,4])\n","\n","x_b = np.c_[np.ones((x.shape[0],1)),x]\n","\n","def cost_function(theta, x, y, N):\n","  y_hat = x.dot(theta)\n","  c = (1/(2*N))*np.sum((y_hat-y)**2)\n","  return c\n","\n","def stochastic_gradient_descent(alpha, x, y, ep=0.001, max_iter=10000):\n","  converged = False\n","  iter = 0\n","  N = x.shape[0] # number of samples\n","  print(\"Num of data = \",N)\n","\n","  # initial theta\n","  theta =  np.random.random((x.shape[1],1))\n","  print(\"Init theta.shape = \",theta.shape)\n","\n","  # total error, J(theta)\n","  J = cost_function(theta, x, y, N)\n","  print(\"First J = \",J)\n","\n","  # Iterate Loop\n","  while not converged:\n","    for i in range(N):\n","      y_hat = x[i].dot(theta)\n","      diff = y_hat - y[i]\n","      grad = x[i].reshape(1,-1).T.dot(diff)\n","\n","      grad = grad.reshape(-1, 1)  # Ensure grad is a column vector\n","\n","      theta = theta - alpha * grad\n","\n","      assert theta.shape == (3,1) #This line makes sure that the shape of theta is still be the same.\n","\n","    # error\n","    J2 = cost_function(theta, x, y, N)\n","\n","    if abs(J-J2) <= ep:\n","        print(\"       Converged, iterations: \", iter, \"/\", max_iter)\n","        converged = True\n","\n","    J = J2   # update error\n","    iter += 1  # update iter\n","\n","    if iter == max_iter:\n","        print('       Max iterations exceeded!')\n","        converged = True\n","\n","  #print(\"End converged iter = \",iter)\n","  return theta\n","\n","if __name__ == '__main__':\n","\n","  print(\"start main\")\n","  print(x_b.shape)\n","  y = y.reshape(-1,1)\n","  print(y.shape)\n","\n","  alpha = 0.01 # learning rate\n","  #Training process\n","  theta = stochastic_gradient_descent(alpha, x_b, y, ep=0.000000000001, max_iter=1000000)\n","  print (\"Theta = \", theta)\n","\n","  #predict trainned x\n","  xtest = np.array([[4,9]])\n","  xtest_b = np.c_[np.ones((xtest.shape[0],1)),xtest]\n","  y_p = xtest_b.dot(theta)\n","  print(\"y predict = \",y_p)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9Rl_BZzmm-K","executionInfo":{"status":"ok","timestamp":1724775598703,"user_tz":-420,"elapsed":3676,"user":{"displayName":"Tanutpong Kunakornkasem","userId":"13209845585212162523"}},"outputId":"1a0c8c81-08b4-4c3a-f78d-98b501d39864"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["start main\n","(3, 3)\n","(3, 1)\n","Num of data =  3\n","Init theta.shape =  (3, 1)\n","First J =  4.729380649088009\n","       Converged, iterations:  76643 / 1000000\n","Theta =  [[ 6.99940575]\n"," [14.99874255]\n"," [-5.99945757]]\n","y predict =  [[12.99925781]]\n","time: 3.27 s (started: 2024-08-27 16:19:54 +00:00)\n"]}]},{"cell_type":"code","source":["# Mini Batch Gradient descent (Multiple linear regression)\n","\n","x = np.array([[0,1],[2,6],[3,8]]) # x1, x2\n","y = np.array([1,1,4])\n","\n","x_b = np.c_[np.ones((x.shape[0],1)),x]\n","\n","def cost_function(theta, x, y, N):\n","    y_hat = x.dot(theta)\n","    c = (1/(2*N)) * np.sum((y_hat-y)**2)\n","    return c\n","\n","def mini_batch_gradient_descent(alpha, x, y, batch_size=2, ep=0.001, max_iter=10000):\n","    converged = False\n","    iter = 0\n","    N = x.shape[0]  # number of samples\n","    print(\"Num of data = \", N)\n","\n","    # initial theta\n","    theta = np.random.random((x.shape[1], 1))\n","    print(\"Init theta.shape = \", theta.shape)\n","\n","    # total error, J(theta)\n","    J = cost_function(theta, x, y, N)\n","    print(\"First J = \", J)\n","\n","    # Iterate Loop\n","    while not converged and iter < max_iter:\n","        for i in range(0, N, batch_size):\n","            # Create mini-batch\n","            x_batch = x[i:i+batch_size]\n","            y_batch = y[i:i+batch_size]\n","\n","            # Predict\n","            y_hat = x_batch.dot(theta)\n","\n","            # Calculate gradient\n","            diff = y_hat - y_batch\n","            grad = x_batch.T.dot(diff)\n","\n","            # Update theta\n","            theta = theta - alpha * (1/batch_size) * grad\n","\n","            assert theta.shape == (3, 1)  # Ensure theta's shape remains the same\n","\n","        # Calculate new cost\n","        J2 = cost_function(theta, x, y, N)\n","\n","        if abs(J-J2) <= ep:\n","            print(\"       Converged, iterations: \", iter, \"/\", max_iter)\n","            converged = True\n","\n","        J = J2  # update error\n","        iter += 1  # update iter\n","\n","        if iter == max_iter:\n","            print('       Max iterations exceeded!')\n","            converged = True\n","\n","    return theta\n","\n","if __name__ == '__main__':\n","\n","    print(\"start main\")\n","    print(x_b.shape)\n","    y = y.reshape(-1, 1)\n","    print(y.shape)\n","\n","    alpha = 0.01  # learning rate\n","    # Training process\n","    theta = mini_batch_gradient_descent(alpha, x_b, y, batch_size=2, ep=0.000000000001, max_iter=1000000)\n","    print(\"Theta = \", theta)\n","\n","    # predict trained x\n","    xtest = np.array([[4, 9]])\n","    xtest_b = np.c_[np.ones((xtest.shape[0], 1)), xtest]\n","    y_p = xtest_b.dot(theta)\n","    print(\"y predict = \", y_p)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZGkk_tDmuSd","executionInfo":{"status":"ok","timestamp":1724775669496,"user_tz":-420,"elapsed":5094,"user":{"displayName":"Tanutpong Kunakornkasem","userId":"13209845585212162523"}},"outputId":"44391f51-e65f-4241-d25e-c330f765cd1a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["start main\n","(3, 3)\n","(3, 1)\n","Num of data =  3\n","Init theta.shape =  (3, 1)\n","First J =  2.136822272756809\n","       Converged, iterations:  169468 / 1000000\n","Theta =  [[ 6.99904362]\n"," [14.99793086]\n"," [-5.99911606]]\n","y predict =  [[12.99872249]]\n","time: 4.14 s (started: 2024-08-27 16:21:04 +00:00)\n"]}]}]}